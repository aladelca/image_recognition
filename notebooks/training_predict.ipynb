{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "#os.chdir('../src')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from model.neural_network import ImageRecognition\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "os.chdir('..')\n",
    "def load_images_from_folder(folder_path, target_size=(256, 256), label = None):\n",
    "    \"\"\"\n",
    "    Carga imágenes desde una carpeta, las redimensiona y las convierte en arrays.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path (str): Ruta de la carpeta que contiene las imágenes.\n",
    "    - target_size (tuple): Tamaño al que se redimensionarán las imágenes (ancho, alto).\n",
    "\n",
    "    Returns:\n",
    "    - images_array (numpy.ndarray): Array de imágenes.\n",
    "    - labels (list): Lista de nombres de archivo (opcionalmente puede ser la clase).\n",
    "    \"\"\"\n",
    "    images_list = []  # Cambiamos el nombre a `images_list` para evitar confusión\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # Redimensionar imagen al tamaño deseado\n",
    "                img_resized = img.resize(target_size)\n",
    "                # Convertir a array\n",
    "                img_array = np.array(img_resized)\n",
    "                # Asegurarse de que tiene 3 canales (RGB)\n",
    "                if img_array.ndim == 2:  # Imagen en escala de grises\n",
    "                    img_array = np.stack((img_array,) * 3, axis=-1)\n",
    "                elif img_array.shape[-1] == 4:  # Imagen RGBA\n",
    "                    img_array = img_array[..., :3]\n",
    "                \n",
    "                images_list.append(img_array)  # Agregar a la lista\n",
    "                labels.append(label)  # Podrías extraer clases desde el nombre si es necesario\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen {file_path}: {e}\")\n",
    "    \n",
    "    # Convertir la lista final a un array de NumPy\n",
    "    images_array = np.array(images_list)\n",
    "    return images_array, labels\n",
    "images_array = np.empty((0, 256, 256, 3))\n",
    "labels = []\n",
    "for i in glob.glob('data_exercise/*'):\n",
    "    images_array_, labels_ = load_images_from_folder(i, target_size=(256, 256), label = i.split('/')[1])\n",
    "    images_array = np.concatenate((images_array, images_array_), axis=0)\n",
    "    labels = labels + labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "images_array_esc = images_array / 255.\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images_array_esc, labels, test_size=0.3, random_state=123)\n",
    "x_training, x_val, y_training, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=123)\n",
    "\n",
    "y_train_cat = pd.get_dummies(y_training).values * 1\n",
    "y_test_cat = pd.get_dummies(y_test).values * 1\n",
    "y_val_cat = pd.get_dummies(y_val).values * 1\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# Assuming x_train, y_train_cat, x_test, y_test_cat are numpy arrays\n",
    "x_train_tensor = torch.tensor(x_training, dtype=torch.float32).permute(0, 3, 1, 2)  # Convert to NCHW\n",
    "y_train_tensor = torch.tensor(y_train_cat.argmax(axis=1), dtype=torch.long)  # Convert one-hot to class indices\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32).permute(0, 3, 1, 2)  # Convert to NCHW\n",
    "y_val_tensor = torch.tensor(y_val_cat.argmax(axis=1), dtype=torch.long)  # Convert one-hot to class indices\n",
    "\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32).permute(0, 3, 1, 2)  # Convert to NCHW\n",
    "y_test_tensor = torch.tensor(y_test_cat.argmax(axis=1), dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 37.6782, Val Accuracy: 0.2012\n",
      "Epoch 2/10, Loss: 36.2953, Val Accuracy: 0.3841\n",
      "Epoch 3/10, Loss: 32.6413, Val Accuracy: 0.4207\n",
      "Epoch 4/10, Loss: 26.3567, Val Accuracy: 0.4878\n",
      "Epoch 5/10, Loss: 19.9001, Val Accuracy: 0.6159\n",
      "Epoch 6/10, Loss: 12.7411, Val Accuracy: 0.6220\n",
      "Epoch 7/10, Loss: 7.5875, Val Accuracy: 0.7317\n",
      "Epoch 8/10, Loss: 4.0166, Val Accuracy: 0.6707\n",
      "Epoch 9/10, Loss: 2.4877, Val Accuracy: 0.7073\n",
      "Epoch 10/10, Loss: 1.9820, Val Accuracy: 0.7073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Model fitted successfully'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = ImageRecognition(num_classes=6)\n",
    "model.to(device)\n",
    "\n",
    "model.fit(criterion, train_loader, val_loader, device, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866096866096866"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score ##\n",
    "accuracy_score(np.array(model.predict(x_test_tensor, batch_size, device)), np.array([i.item() for i in y_test_tensor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model saved to custom_vgg16.pth'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model(\"custom_vgg16.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 4, 5, 5, 0, 2, 4, 0, 3, 0, 3, 1, 2, 4, 5, 4, 2, 0, 4, 5, 1, 0, 1,\n",
       "        4, 2, 0, 2, 0, 4, 5, 2, 3, 4, 0, 4, 3, 4, 0, 0, 2, 4, 2, 4, 3, 3, 0, 2,\n",
       "        3, 3, 1, 4, 1, 0, 0, 1, 1, 2, 2, 0, 1, 5, 2, 3, 0, 0, 1, 0, 5, 3, 3, 1,\n",
       "        5, 3, 3, 3, 1, 0, 2, 1, 3, 4, 4, 4, 3, 1, 4, 2, 5, 1, 1, 3, 4, 3, 0, 2,\n",
       "        4, 0, 1, 3, 5, 1, 0, 2, 1, 4, 0, 5, 2, 4, 5, 0, 5, 2, 3, 0, 2, 0, 1, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 4, 4, 5, 3, 2, 5, 3, 0, 2, 0, 3, 0, 0, 0, 2, 5, 4,\n",
       "        1, 3, 4, 3, 4, 4, 3, 1, 0, 3, 2, 0, 1, 4, 0, 2, 3, 4, 3, 2, 3, 3, 0, 5,\n",
       "        1, 3, 2, 1, 0, 0, 5, 4, 3, 0, 1, 1, 1, 1, 0, 3, 0, 3, 1, 1, 0, 3, 1, 4,\n",
       "        5, 3, 0, 0, 2, 4, 3, 3, 5, 0, 3, 1, 1, 2, 5, 0, 1, 1, 2, 3, 4, 4, 0, 0,\n",
       "        0, 3, 4, 3, 2, 1, 0, 1, 2, 4, 5, 5, 1, 3, 3, 4, 0, 5, 3, 4, 3, 3, 3, 0,\n",
       "        1, 2, 3, 4, 3, 2, 3, 5, 1, 1, 5, 0, 5, 3, 1, 2, 3, 0, 0, 4, 3, 0, 0, 3,\n",
       "        0, 3, 3, 3, 0, 2, 0, 0, 5, 0, 3, 2, 4, 3, 0, 2, 5, 3, 1, 1, 5, 0, 5, 2,\n",
       "        0, 5, 0, 4, 1, 3, 3, 3, 2, 2, 3, 0, 0, 5, 0, 2, 1, 4, 4, 0, 4, 3, 3, 3,\n",
       "        0, 0, 3, 0, 3, 3, 0, 4, 4, 2, 1, 4, 5, 4, 2, 0, 5, 4, 3, 3, 2, 1, 1, 4,\n",
       "        3, 3, 1, 1, 0, 2, 3, 0, 1, 3, 3, 3, 1, 0, 4], device='mps:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_from_load(x_test_tensor, \n",
    "                        \"custom_vgg16.pth\",\n",
    "                        device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_recognition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
